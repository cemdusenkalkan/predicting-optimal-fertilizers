{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚀 SMART FERTILIZER RECOMMENDATION MODEL\n",
        "# Built on insights from deep feature analysis\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Advanced libraries\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.precision', 4)\n",
        "\n",
        "print(\"🎯 SMART FERTILIZER RECOMMENDATION MODEL\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Building optimized model based on deep analysis insights...\")\n",
        "\n",
        "# Load datasets\n",
        "data_dir = Path('/kaggle/input/playground-series-s5e6/')\n",
        "train_df = pd.read_csv(data_dir / 'train.csv')\n",
        "test_df = pd.read_csv(data_dir / 'test.csv')\n",
        "\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "print(f\"Test shape: {test_df.shape}\")\n",
        "print(\"✅ Data loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 OPTIMIZED FEATURE ENGINEERING\n",
        "# Based on deep analysis insights from our research\n",
        "\n",
        "print(\"\\n🔧 APPLYING OPTIMIZED FEATURE ENGINEERING\")\n",
        "print(\"Based on extensive analysis, we identified the most valuable features:\")\n",
        "print(\"✅ Environmental efficiency features (climate_comfort, water_availability)\")\n",
        "print(\"✅ NPK interaction features (N_efficiency, K_leaching_risk)\")  \n",
        "print(\"✅ Crop-soil combinations (strongest predictors)\")\n",
        "print(\"✅ Key feature interactions with proven synergy\")\n",
        "\n",
        "def create_smart_features(df):\n",
        "    \"\"\"Create features based on deep analysis insights\"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # TOP PERFORMING FEATURES FROM ANALYSIS\n",
        "    # 1. Environmental efficiency features (top performers from MI analysis)\n",
        "    df['water_availability'] = df['Humidity'] * df['Moisture'] / 100\n",
        "    df['climate_comfort'] = (\n",
        "        (df['Temparature'] - df['Temparature'].min()) / (df['Temparature'].max() - df['Temparature'].min()) +\n",
        "        (df['Humidity'] - df['Humidity'].min()) / (df['Humidity'].max() - df['Humidity'].min()) +\n",
        "        (df['Moisture'] - df['Moisture'].min()) / (df['Moisture'].max() - df['Moisture'].min())\n",
        "    ) / 3\n",
        "    \n",
        "    # 2. NPK efficiency features (highest MI scores)\n",
        "    df['N_efficiency'] = df['Nitrogen'] * df['water_availability']\n",
        "    df['K_leaching_risk'] = df['Potassium'] * df['Moisture'] / df['Humidity']\n",
        "    \n",
        "    # 3. Key NPK ratios (controlled for extreme values)\n",
        "    df['N_P_ratio'] = np.clip(df['Nitrogen'] / (df['Phosphorous'] + 1e-6), 0, 100)\n",
        "    df['N_K_ratio'] = np.clip(df['Nitrogen'] / (df['Potassium'] + 1e-6), 0, 100)\n",
        "    df['P_K_ratio'] = np.clip(df['Phosphorous'] / (df['Potassium'] + 1e-6), 0, 100)\n",
        "    \n",
        "    # 4. Top interaction from analysis: N_efficiency × water_availability (0.0062 synergy)\n",
        "    df['N_efficiency_water_interaction'] = df['N_efficiency'] * df['water_availability']\n",
        "    \n",
        "    # 5. Environmental ratios (high importance)\n",
        "    df['temp_moisture_ratio'] = df['Temparature'] / (df['Moisture'] + 1e-6)\n",
        "    df['npk_env_ratio'] = (df['Nitrogen'] + df['Phosphorous'] + df['Potassium']) / (df['climate_comfort'] + 1e-6)\n",
        "    \n",
        "    # 6. Critical crop-soil interactions (Cramér's V: 0.0353)\n",
        "    df['crop_soil_combo'] = df['Crop Type'] + \"_\" + df['Soil Type']\n",
        "    \n",
        "    # 7. Domain knowledge features\n",
        "    water_demanding_crops = ['Paddy', 'Sugarcane']\n",
        "    moisture_retaining_soils = ['Clayey', 'Black', 'Loamy']\n",
        "    df['crop_water_demand'] = df['Crop Type'].isin(water_demanding_crops).astype(int)\n",
        "    df['soil_water_retention'] = df['Soil Type'].isin(moisture_retaining_soils).astype(int)\n",
        "    df['water_match'] = df['crop_water_demand'] * df['soil_water_retention']\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Apply feature engineering\n",
        "train_engineered = create_smart_features(train_df)\n",
        "test_engineered = create_smart_features(test_df)\n",
        "\n",
        "print(f\"\\n✅ Smart features created\")\n",
        "print(f\"Feature count: {train_df.shape[1]} → {train_engineered.shape[1]}\")\n",
        "print(f\"New features added: {train_engineered.shape[1] - train_df.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 OPTIMAL FEATURE SELECTION\n",
        "# Based on mutual information and random forest analysis\n",
        "\n",
        "print(\"\\n📊 SELECTING TOP FEATURES\")\n",
        "print(\"Features ranked by our deep analysis (MI + RF importance):\")\n",
        "\n",
        "# Features ranked by our analysis results\n",
        "top_features = [\n",
        "    # Environmental efficiency (top performers: combined_score > 0.018)\n",
        "    'climate_comfort', 'water_availability', 'N_efficiency', 'K_leaching_risk',\n",
        "    \n",
        "    # NPK ratios (controlled for extremes, high MI scores)\n",
        "    'N_P_ratio', 'N_K_ratio', 'P_K_ratio',\n",
        "    \n",
        "    # Key interactions (proven synergy > 0.002)\n",
        "    'N_efficiency_water_interaction', 'temp_moisture_ratio', 'npk_env_ratio',\n",
        "    \n",
        "    # Original strong features\n",
        "    'Nitrogen', 'Phosphorous', 'Potassium', 'Temparature', 'Humidity', 'Moisture',\n",
        "    \n",
        "    # Domain features (agricultural knowledge)\n",
        "    'crop_water_demand', 'soil_water_retention', 'water_match'\n",
        "]\n",
        "\n",
        "# Categorical features (strongest predictors from Chi-square analysis)\n",
        "categorical_features = ['Crop Type', 'Soil Type', 'crop_soil_combo']\n",
        "\n",
        "print(f\"Selected {len(top_features)} numerical + {len(categorical_features)} categorical features\")\n",
        "\n",
        "# Show some key insights from our analysis\n",
        "print(\"\\n🔬 Key insights from deep analysis:\")\n",
        "print(\"• climate_comfort: Combined MI+RF score = 0.0211 (top feature)\")\n",
        "print(\"• N_efficiency × water_availability: 0.0062 synergy (best interaction)\")\n",
        "print(\"• Crop-soil combinations: 55 unique, up to 18.8% dominance\")\n",
        "print(\"• NPK ratios outperform absolute values\")\n",
        "print(\"• Environmental interactions provide significant value-add\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔄 DATA PREPARATION FOR MODELING\n",
        "\n",
        "print(\"\\n🔄 PREPARING DATA FOR MODELING\")\n",
        "\n",
        "# Encode categorical features\n",
        "le_dict = {}\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    train_engineered[f'{col}_encoded'] = le.fit_transform(train_engineered[col])\n",
        "    test_engineered[f'{col}_encoded'] = le.transform(test_engineered[col])\n",
        "    le_dict[col] = le\n",
        "\n",
        "# Prepare feature matrix\n",
        "categorical_encoded = [f'{col}_encoded' for col in categorical_features]\n",
        "all_features = top_features + categorical_encoded\n",
        "\n",
        "X = train_engineered[all_features]\n",
        "y = train_engineered['Fertilizer Name']\n",
        "\n",
        "# Encode target\n",
        "le_target = LabelEncoder()\n",
        "y_encoded = le_target.fit_transform(y)\n",
        "\n",
        "print(f\"Final feature matrix: {X.shape}\")\n",
        "print(f\"Target classes: {len(le_target.classes_)} fertilizers\")\n",
        "print(f\"Target distribution: {pd.Series(y).value_counts().to_dict()}\")\n",
        "\n",
        "# Display feature overview\n",
        "print(f\"\\n📈 Feature Overview:\")\n",
        "print(f\"Environmental features: {[f for f in all_features if any(x in f.lower() for x in ['climate', 'water', 'temp', 'humidity', 'moisture'])]}\")\n",
        "print(f\"NPK features: {[f for f in all_features if any(x in f.lower() for x in ['nitrogen', 'phosphorous', 'potassium', 'n_p', 'n_k', 'p_k', 'npk'])]}\")\n",
        "print(f\"Interaction features: {[f for f in all_features if 'interaction' in f.lower() or 'ratio' in f.lower()]}\")\n",
        "print(f\"Domain features: {[f for f in all_features if any(x in f.lower() for x in ['crop', 'soil', 'water_match'])]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🤖 SMART MODEL ENSEMBLE\n",
        "# Optimized ensemble based on analysis insights\n",
        "\n",
        "print(\"\\n🤖 BUILDING SMART MODEL ENSEMBLE\")\n",
        "\n",
        "# Split data for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, \n",
        "                                                  random_state=42, stratify=y_encoded)\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}\")\n",
        "\n",
        "# Model ensemble optimized for this dataset\n",
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=15,\n",
        "        min_samples_split=50,\n",
        "        min_samples_leaf=20,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    'GradientBoosting': GradientBoostingClassifier(\n",
        "        n_estimators=150,\n",
        "        max_depth=8,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'LogisticRegression': LogisticRegression(\n",
        "        random_state=42,\n",
        "        max_iter=1000,\n",
        "        multi_class='ovr',\n",
        "        C=1.0\n",
        "    )\n",
        "}\n",
        "\n",
        "print(f\"\\nTraining {len(models)} models...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 MODEL TRAINING & EVALUATION\n",
        "\n",
        "# Train and evaluate models\n",
        "results = {}\n",
        "trained_models = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n🔄 Training {name}...\")\n",
        "    \n",
        "    # Scale features for Logistic Regression\n",
        "    if name == 'LogisticRegression':\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_val_scaled = scaler.transform(X_val)\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        val_pred = model.predict(X_val_scaled)\n",
        "        trained_models[name] = (model, scaler)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        val_pred = model.predict(X_val)\n",
        "        trained_models[name] = (model, None)\n",
        "    \n",
        "    # Evaluate\n",
        "    val_accuracy = accuracy_score(y_val, val_pred)\n",
        "    \n",
        "    # Cross-validation score\n",
        "    if name == 'LogisticRegression':\n",
        "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "    else:\n",
        "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "    \n",
        "    results[name] = {\n",
        "        'val_accuracy': val_accuracy,\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std()\n",
        "    }\n",
        "    \n",
        "    print(f\"  ✅ Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    print(f\"  📈 CV Score: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
        "\n",
        "# Select best model\n",
        "best_model_name = max(results.keys(), key=lambda k: results[k]['cv_mean'])\n",
        "best_model, best_scaler = trained_models[best_model_name]\n",
        "\n",
        "print(f\"\\n🏆 BEST MODEL: {best_model_name}\")\n",
        "print(f\"📊 CV Score: {results[best_model_name]['cv_mean']:.4f} ± {results[best_model_name]['cv_std']:.4f}\")\n",
        "print(f\"🎯 Validation Accuracy: {results[best_model_name]['val_accuracy']:.4f}\")\n",
        "\n",
        "# Model comparison\n",
        "print(f\"\\n📋 Model Comparison:\")\n",
        "for name, result in results.items():\n",
        "    print(f\"{name:15s}: CV={result['cv_mean']:.4f} ± {result['cv_std']:.4f}, Val={result['val_accuracy']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📈 FEATURE IMPORTANCE ANALYSIS\n",
        "\n",
        "print(\"\\n📈 FEATURE IMPORTANCE ANALYSIS\")\n",
        "\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': all_features,\n",
        "        'Importance': best_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "    \n",
        "    print(f\"\\nTop 15 Most Important Features in {best_model_name}:\")\n",
        "    for i, row in importance_df.head(15).iterrows():\n",
        "        print(f\"{row['Feature']:25s}: {row['Importance']:.4f}\")\n",
        "    \n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    top_20 = importance_df.head(20)\n",
        "    \n",
        "    # Create color map based on feature type\n",
        "    colors = []\n",
        "    for feature in top_20['Feature']:\n",
        "        if any(x in feature.lower() for x in ['crop', 'soil']):\n",
        "            colors.append('#2E8B57')  # Green for domain features\n",
        "        elif any(x in feature.lower() for x in ['n_', 'p_', 'k_', 'nitrogen', 'phosphorous', 'potassium']):\n",
        "            colors.append('#FF6347')  # Red for NPK features\n",
        "        elif any(x in feature.lower() for x in ['climate', 'water', 'temp', 'humidity', 'moisture']):\n",
        "            colors.append('#4169E1')  # Blue for environmental\n",
        "        else:\n",
        "            colors.append('#9370DB')  # Purple for interactions\n",
        "    \n",
        "    bars = plt.barh(range(len(top_20)), top_20['Importance'], color=colors)\n",
        "    plt.yticks(range(len(top_20)), top_20['Feature'])\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.title(f'Top 20 Feature Importance - {best_model_name}')\n",
        "    plt.gca().invert_yaxis()\n",
        "    \n",
        "    # Add legend\n",
        "    legend_elements = [\n",
        "        plt.Rectangle((0,0),1,1, color='#2E8B57', label='Domain Features'),\n",
        "        plt.Rectangle((0,0),1,1, color='#FF6347', label='NPK Features'),\n",
        "        plt.Rectangle((0,0),1,1, color='#4169E1', label='Environmental'),\n",
        "        plt.Rectangle((0,0),1,1, color='#9370DB', label='Interactions')\n",
        "    ]\n",
        "    plt.legend(handles=legend_elements, loc='lower right')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Analyze feature importance by category\n",
        "    print(f\"\\n🔍 Feature Importance by Category:\")\n",
        "    env_features = [f for f in importance_df['Feature'] if any(x in f.lower() for x in ['climate', 'water', 'temp', 'humidity', 'moisture'])]\n",
        "    npk_features = [f for f in importance_df['Feature'] if any(x in f.lower() for x in ['nitrogen', 'phosphorous', 'potassium', 'n_p', 'n_k', 'p_k', 'npk'])]\n",
        "    domain_features = [f for f in importance_df['Feature'] if any(x in f.lower() for x in ['crop', 'soil'])]\n",
        "    \n",
        "    print(f\"Environmental avg importance: {importance_df[importance_df['Feature'].isin(env_features)]['Importance'].mean():.4f}\")\n",
        "    print(f\"NPK features avg importance: {importance_df[importance_df['Feature'].isin(npk_features)]['Importance'].mean():.4f}\")\n",
        "    print(f\"Domain features avg importance: {importance_df[importance_df['Feature'].isin(domain_features)]['Importance'].mean():.4f}\")\n",
        "\n",
        "else:\n",
        "    print(f\"{best_model_name} does not provide feature importance scores.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 GENERATE PREDICTIONS & SUBMISSION\n",
        "\n",
        "print(\"\\n🎯 GENERATING PREDICTIONS\")\n",
        "\n",
        "# Prepare test data\n",
        "X_test = test_engineered[all_features]\n",
        "print(f\"Test data shape: {X_test.shape}\")\n",
        "\n",
        "# Make predictions with best model\n",
        "print(f\"Making predictions with {best_model_name}...\")\n",
        "\n",
        "if best_scaler:\n",
        "    X_test_scaled = best_scaler.transform(X_test)\n",
        "    test_predictions = best_model.predict(X_test_scaled)\n",
        "    test_probabilities = best_model.predict_proba(X_test_scaled)\n",
        "else:\n",
        "    test_predictions = best_model.predict(X_test)\n",
        "    test_probabilities = best_model.predict_proba(X_test)\n",
        "\n",
        "# Convert back to fertilizer names\n",
        "test_predictions_labels = le_target.inverse_transform(test_predictions)\n",
        "\n",
        "# Analyze prediction confidence\n",
        "max_probs = np.max(test_probabilities, axis=1)\n",
        "print(f\"Prediction confidence stats:\")\n",
        "print(f\"  Mean confidence: {max_probs.mean():.4f}\")\n",
        "print(f\"  Min confidence: {max_probs.min():.4f}\")\n",
        "print(f\"  Max confidence: {max_probs.max():.4f}\")\n",
        "print(f\"  High confidence (>0.8): {(max_probs > 0.8).sum()} predictions ({(max_probs > 0.8).mean()*100:.1f}%)\")\n",
        "\n",
        "# Create submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_engineered['id'],\n",
        "    'Fertilizer Name': test_predictions_labels\n",
        "})\n",
        "\n",
        "# Analyze prediction distribution\n",
        "pred_dist = pd.Series(test_predictions_labels).value_counts()\n",
        "print(f\"\\n📊 Prediction Distribution:\")\n",
        "for fertilizer, count in pred_dist.items():\n",
        "    percentage = count / len(test_predictions_labels) * 100\n",
        "    print(f\"  {fertilizer:10s}: {count:6d} ({percentage:5.1f}%)\")\n",
        "\n",
        "# Save submission\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(f\"\\n✅ Submission saved to submission.csv\")\n",
        "print(f\"📄 File contains {len(submission)} predictions\")\n",
        "\n",
        "# Final summary\n",
        "print(f\"\\n🏁 FINAL SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"🎯 Best Model: {best_model_name}\")\n",
        "print(f\"📊 Cross-validation Score: {results[best_model_name]['cv_mean']:.4f} ± {results[best_model_name]['cv_std']:.4f}\")\n",
        "print(f\"🎲 Validation Accuracy: {results[best_model_name]['val_accuracy']:.4f}\")\n",
        "print(f\"🔧 Features Used: {len(all_features)} engineered features\")\n",
        "print(f\"📈 Top Feature: {importance_df.iloc[0]['Feature'] if hasattr(best_model, 'feature_importances_') else 'N/A'}\")\n",
        "print(f\"🚀 Ready for submission!\")\n",
        "\n",
        "# Display first few predictions as example\n",
        "print(f\"\\n📋 Sample Predictions:\")\n",
        "sample_preds = submission.head(10)\n",
        "for idx, row in sample_preds.iterrows():\n",
        "    conf = max_probs[idx]\n",
        "    print(f\"  ID {row['id']:6d}: {row['Fertilizer Name']:10s} (confidence: {conf:.3f})\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
